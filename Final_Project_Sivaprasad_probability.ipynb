{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5840cfa",
   "metadata": {},
   "source": [
    "# <span style=\"color:Brown\"> Classification Using Bagging\n",
    "</span>\n",
    "\n",
    "#### <span style=\"color:black\"> Author : Sivaprasad Puthumadthil rameshan nair </span>\n",
    "\n",
    "<br>\n",
    "\n",
    "## <span style=\"color:blue\"> Aim: </span>\n",
    "\n",
    "Implement a basic bagging algorithm and apply it to a classification model and compare the performance of the base model with bagging ensemble.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### What is bagging ? \n",
    "\n",
    "Bagging is an ensemble machine learning technique that involves training multiple models independently on different subsets of the training data and then combining their predictions. The main idea of bagging is to reduce overfitting and improve the performance and robustness of the model.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### The various steps involved in the project :\n",
    "\n",
    "    - Data loading and analysis\n",
    "    - Prediction using Base classifier model\n",
    "    - Prediction using Bagging classifier\n",
    "    \n",
    "<br>\n",
    "\n",
    "#### Concepts used :\n",
    "\n",
    "Bagging.\n",
    "\n",
    "<br>\n",
    "    \n",
    "## Data :\n",
    "\n",
    "Heart Disease UCI Dataset (https://archive.ics.uci.edu/dataset/45/heart+disease)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898b5c5",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Data loading and analysis </span>\n",
    "\n",
    "Import all the required packages for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7870b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import column_or_1d\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cb861",
   "metadata": {},
   "source": [
    "#### Fetch data from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cf0808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\puthu\\anaconda3\\lib\\site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27d797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "heart_disease = fetch_ucirepo(id=45) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29864393",
   "metadata": {},
   "source": [
    "## Analysing the Data :\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In this section we will check the number of rows , number of coloumns and understand how the data is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db018eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (303, 13)\n",
      "shape of y (303, 1)\n"
     ]
    }
   ],
   "source": [
    "# get feature matrix (input data)\n",
    "X = heart_disease.data.features \n",
    "\n",
    "# get target variable (output)\n",
    "y = heart_disease.data.targets \n",
    "print(\"shape of X\", X.shape)\n",
    "print(\"shape of y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477e41fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows 303 and number of coloumns 13\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = X.shape\n",
    "print(f\"The number of rows {num_rows} and number of coloumns {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278616f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 coloumns in data set :\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "    ca  thal  \n",
      "0  0.0   6.0  \n",
      "1  3.0   3.0  \n",
      "2  2.0   7.0  \n",
      "3  0.0   3.0  \n",
      "4  0.0   3.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"The first 5 coloumns in data set :\\n\",X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25147e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        299 non-null    float64\n",
      " 12  thal      301 non-null    float64\n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   num     303 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58caf101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "      <td>4.734219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>1.939706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal  \n",
       "count  301.000000  \n",
       "mean     4.734219  \n",
       "std      1.939706  \n",
       "min      3.000000  \n",
       "25%      3.000000  \n",
       "50%      3.000000  \n",
       "75%      7.000000  \n",
       "max      7.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279dc824",
   "metadata": {},
   "source": [
    "<br>\n",
    "Check for null entries. if there is any null entries let's remove them.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07227d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (303, 13)\n",
      "shape of y (303, 1)\n",
      "shape of X after cleaning (297, 13)\n",
      "shape of y after cleaning (297, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X\", X.shape)\n",
    "print(\"shape of y\", y.shape)\n",
    "\n",
    "#check if any null rows are present\n",
    "rows_with_null_X = np.any(np.isnan(X), axis=1)\n",
    "\n",
    "#remove the null rows from both x and y \n",
    "X_cleaned = X[~rows_with_null_X]\n",
    "y_cleaned = y[~rows_with_null_X]\n",
    "print(\"shape of X after cleaning\", X_cleaned.shape)\n",
    "print(\"shape of y after cleaning\", y_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae9af5",
   "metadata": {},
   "source": [
    "as you can see , we removed 6 rows which had null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd067c9",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Prediction using Base classifier model </span>\n",
    "\n",
    "<br>\n",
    "\n",
    "now let's split the data for testing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc05a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X train (237, 13) and shape of y train (237, 1)\n",
      "shape of X test (60, 13) and shape of y test (60, 1)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to train and test data for training and testing the model\n",
    "# test size = 20% and train size will be 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"shape of X train {X_train.shape} and shape of y train {y_train.shape}\")\n",
    "print(f\"shape of X test {X_test.shape} and shape of y test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1670ef",
   "metadata": {},
   "source": [
    "\n",
    "now let's train and predict the data using a basic classifier (DescionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e3ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Base Classifier: 0.48333333333333334\n"
     ]
    }
   ],
   "source": [
    "# let's define the base classifier and train the model , the random_state is set to 42 so that every time \n",
    "# the random descisions made during the building remain same\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "base_classifier.fit(X_train, y_train)\n",
    "\n",
    "#now let's test the model and get the predicted y value.\n",
    "\n",
    "y_predicted = base_classifier.predict(X_test)\n",
    "\n",
    "# let's calculate the accuracy score \n",
    "accuracy_score_base_classifier = accuracy_score(y_test, y_predicted)\n",
    "print(f'Accuracy of Base Classifier: {accuracy_score_base_classifier}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46220a",
   "metadata": {},
   "source": [
    "##  <span style=\"color:blue\"> Prediction using Bagging classifier </span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f70df0",
   "metadata": {},
   "source": [
    "    Define a bagging classifier with the base classifier.\n",
    "    \n",
    "    bagging classifier can be called using inbuilt method BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e10a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped y train  (237,)\n",
      "Accuracy after bagging : 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "# define the bahhing classifier with base classifier (DecisionTree)\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, max_samples=0.8, random_state=422)\n",
    "\n",
    "# reshape the y to be a 1d data\n",
    "y_train_reshaped = y_train.to_numpy().ravel()\n",
    "y_test_reshaped = y_test.to_numpy().ravel()\n",
    "\n",
    "# train the model\n",
    "bagging_classifier.fit(X_train, y_train_reshaped)\n",
    "print(\"reshaped y train \",y_train_reshaped.shape)\n",
    "\n",
    "# predict the test values\n",
    "y_pred_bagging = bagging_classifier.predict(X_test)\n",
    "\n",
    "#calculate the accuracy of the bagging model\n",
    "accuracy_bagging = accuracy_score(y_test_reshaped, y_pred_bagging)\n",
    "print(f'Accuracy after bagging : {accuracy_bagging}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e586ea40",
   "metadata": {},
   "source": [
    "as we can see the accuracy after bagging is increased \n",
    "\n",
    "### How the bagging classifier increased the prediction accuracy ?\n",
    "\n",
    "1.Variance Reduction : By training multiple base classifiers on different subsets of the data, bagging helps reduce the variability in individual predictions.<br>\n",
    "2.Bagging can mitigate biases associated with specific training data subsets. <br>\n",
    "3.Bagging promotes better generalization by reducing overfitting.<br>\n",
    "4.Bagging provides stability to the model, as small changes in the training data are less likely to significantly impact the overall predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542d893",
   "metadata": {},
   "source": [
    "##  <span style=\"color:blue\"> Conclusion </span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbd6ca",
   "metadata": {},
   "source": [
    "In this project, we successfully loaded and analyzed the Heart Disease UCI dataset, gaining valuable insights into its structure and features. We started by employing a base classifier, specifically a Decision Tree Classifier, to establish a baseline for comparison. Subsequently, we implemented a Bagging Classifier to enhance predictive accuracy and model robustness. By training multiple instances of the base classifier on diverse subsets of the data, the Bagging Classifier effectively reduced variability in individual predictions. The comprehensive evaluation, including accuracy metrics, provided a clear comparison between the performance of the base classifier and the boosted accuracy achieved through the ensemble learning technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a86b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
